{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn \nimport torch.nn.functional as F \n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T10:45:50.482132Z","iopub.execute_input":"2025-06-14T10:45:50.482336Z","iopub.status.idle":"2025-06-14T10:45:50.486124Z","shell.execute_reply.started":"2025-06-14T10:45:50.482321Z","shell.execute_reply":"2025-06-14T10:45:50.485220Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T10:45:50.488665Z","iopub.execute_input":"2025-06-14T10:45:50.488833Z","iopub.status.idle":"2025-06-14T10:45:50.502399Z","shell.execute_reply.started":"2025-06-14T10:45:50.488820Z","shell.execute_reply":"2025-06-14T10:45:50.501692Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"class SimpleModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.fc1 = nn.Linear(10, 16*1024)\n        self.fc2 = nn.Linear(16*1024, 16*1024)\n        self.fc3 = nn.Linear(16* 1024, 1)\n\n    def forward(self, x):\n        return self.fc3(self.fc2(self.fc1(x)))\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T10:45:50.503058Z","iopub.execute_input":"2025-06-14T10:45:50.503333Z","iopub.status.idle":"2025-06-14T10:45:50.517877Z","shell.execute_reply.started":"2025-06-14T10:45:50.503312Z","shell.execute_reply":"2025-06-14T10:45:50.517201Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"model = SimpleModel().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T10:45:50.518499Z","iopub.execute_input":"2025-06-14T10:45:50.518744Z","iopub.status.idle":"2025-06-14T10:45:53.030036Z","shell.execute_reply.started":"2025-06-14T10:45:50.518719Z","shell.execute_reply":"2025-06-14T10:45:53.029513Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"master_params = [param.data.clone().float() for param in model.parameters()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T10:45:53.030640Z","iopub.execute_input":"2025-06-14T10:45:53.030824Z","iopub.status.idle":"2025-06-14T10:45:53.035785Z","shell.execute_reply.started":"2025-06-14T10:45:53.030809Z","shell.execute_reply":"2025-06-14T10:45:53.035032Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"model.half()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T10:45:53.036657Z","iopub.execute_input":"2025-06-14T10:45:53.036925Z","iopub.status.idle":"2025-06-14T10:45:53.053717Z","shell.execute_reply.started":"2025-06-14T10:45:53.036904Z","shell.execute_reply":"2025-06-14T10:45:53.052993Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"SimpleModel(\n  (fc1): Linear(in_features=10, out_features=16384, bias=True)\n  (fc2): Linear(in_features=16384, out_features=16384, bias=True)\n  (fc3): Linear(in_features=16384, out_features=1, bias=True)\n)"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"class MasterParams(nn.Module):\n    def __init__(self, master_params):\n        super().__init__()\n\n        for i, param in enumerate(master_params):\n            self.register_parameter(f\"param_{i}\", nn.Parameter(param))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T10:45:53.054464Z","iopub.execute_input":"2025-06-14T10:45:53.054708Z","iopub.status.idle":"2025-06-14T10:45:53.067308Z","shell.execute_reply.started":"2025-06-14T10:45:53.054689Z","shell.execute_reply":"2025-06-14T10:45:53.066611Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"master_model = MasterParams(master_params)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T10:45:53.068208Z","iopub.execute_input":"2025-06-14T10:45:53.068753Z","iopub.status.idle":"2025-06-14T10:45:53.082795Z","shell.execute_reply.started":"2025-06-14T10:45:53.068737Z","shell.execute_reply":"2025-06-14T10:45:53.082095Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"optimizer = torch.optim.SGD(master_model.parameters(), lr=1e-3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T10:45:53.083626Z","iopub.execute_input":"2025-06-14T10:45:53.083852Z","iopub.status.idle":"2025-06-14T10:45:53.097527Z","shell.execute_reply.started":"2025-06-14T10:45:53.083828Z","shell.execute_reply":"2025-06-14T10:45:53.096991Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"inputs = torch.randn(1024+512*3, 10, device=device)\ntargets = torch.randn(1024+512*3, 1, device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T10:45:53.098211Z","iopub.execute_input":"2025-06-14T10:45:53.098465Z","iopub.status.idle":"2025-06-14T10:45:53.111627Z","shell.execute_reply.started":"2025-06-14T10:45:53.098442Z","shell.execute_reply":"2025-06-14T10:45:53.111091Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"S = 128.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T10:45:53.112303Z","iopub.execute_input":"2025-06-14T10:45:53.112532Z","iopub.status.idle":"2025-06-14T10:45:53.130607Z","shell.execute_reply.started":"2025-06-14T10:45:53.112511Z","shell.execute_reply":"2025-06-14T10:45:53.130069Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def train():\n    for epoch in range(10):\n    \n        # copy weights from master model into fp16, with half precision\n        for p_master, p_model in zip(master_model.parameters(), model.parameters()):\n            p_model.data.copy_(p_master.data.half())\n    \n        optimizer.zero_grad()\n    \n        # fp16 forward\n        outputs = model(inputs.half())\n        loss = nn.MSELoss()(outputs, targets.half())\n        scaled_loss = S * loss \n    \n        scaled_loss.backward()\n    \n        # unscale grads\n        for p in model.parameters():\n            if p.grad is not None:\n                p.grad.data.div_(S)\n    \n        for p_master, p_model in zip(master_model.parameters(), model.parameters()):\n            if p_model.grad is not None:\n                p_master.grad = p_model.grad.float()\n        optimizer.step() # on unscaled grads\n    \n        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n    \n    for p_master, p_model in zip(master_model.parameters(), model.parameters()):\n        p_model.data.copy_(p_master.data.half())\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T10:45:53.131392Z","iopub.execute_input":"2025-06-14T10:45:53.131612Z","iopub.status.idle":"2025-06-14T10:45:53.150419Z","shell.execute_reply.started":"2025-06-14T10:45:53.131585Z","shell.execute_reply":"2025-06-14T10:45:53.149664Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"%timeit -n 1 -r 2 train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T10:45:53.151232Z","iopub.execute_input":"2025-06-14T10:45:53.151461Z","iopub.status.idle":"2025-06-14T10:45:57.826081Z","shell.execute_reply.started":"2025-06-14T10:45:53.151439Z","shell.execute_reply":"2025-06-14T10:45:57.825481Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 1.083984375\nEpoch 2, Loss: 1.0107421875\nEpoch 3, Loss: 1.0068359375\nEpoch 4, Loss: 1.005859375\nEpoch 5, Loss: 1.005859375\nEpoch 6, Loss: 1.005859375\nEpoch 7, Loss: 1.005859375\nEpoch 8, Loss: 1.005859375\nEpoch 9, Loss: 1.005859375\nEpoch 10, Loss: 1.005859375\nEpoch 1, Loss: 1.005859375\nEpoch 2, Loss: 1.005859375\nEpoch 3, Loss: 1.005859375\nEpoch 4, Loss: 1.005859375\nEpoch 5, Loss: 1.005859375\nEpoch 6, Loss: 1.005859375\nEpoch 7, Loss: 1.005859375\nEpoch 8, Loss: 1.005859375\nEpoch 9, Loss: 1.005859375\nEpoch 10, Loss: 1.005859375\n2.33 s ± 97.7 ms per loop (mean ± std. dev. of 2 runs, 1 loop each)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"Epoch 1, Loss: 1.083984375\nEpoch 2, Loss: 1.0107421875\nEpoch 3, Loss: 1.0068359375\nEpoch 4, Loss: 1.005859375\nEpoch 5, Loss: 1.005859375\nEpoch 6, Loss: 1.005859375\nEpoch 7, Loss: 1.005859375\nEpoch 8, Loss: 1.005859375\nEpoch 9, Loss: 1.005859375\nEpoch 10, Loss: 1.005859375\nEpoch 1, Loss: 1.005859375\nEpoch 2, Loss: 1.005859375\nEpoch 3, Loss: 1.005859375\nEpoch 4, Loss: 1.005859375\nEpoch 5, Loss: 1.005859375\nEpoch 6, Loss: 1.005859375\nEpoch 7, Loss: 1.005859375\nEpoch 8, Loss: 1.005859375\nEpoch 9, Loss: 1.005859375\nEpoch 10, Loss: 1.005859375\n\n\n2.33 s ± 97.7 ms per loop (mean ± std. dev. of 2 runs, 1 loop each)","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_full():\n    for epoch in range(10):\n    \n        # # copy weights from master model into fp16, with half precision\n        # for p_master, p_model in zip(master_model.parameters(), model.parameters()):\n        #     p_model.data.copy_(p_master.data.float())\n    \n        optimizer.zero_grad()\n    \n        # fp16 forward\n        outputs = model(inputs)\n        loss = nn.MSELoss()(outputs, targets)\n        # scaled_loss = S * loss \n    \n        # scaled_loss.backward()\n        loss.backward()\n    \n        # unscale grads\n        # for p in model.parameters():\n        #     if p.grad is not None:\n        #         p.grad.data.div_(S)\n    \n        # for p_master, p_model in zip(master_model.parameters(), model.parameters()):\n        #     if p_model.grad is not None:\n        #         p_master.grad = p_model.grad.data.float()\n        optimizer.step() # on unscaled grads\n    \n        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n    \n    # for p_master, p_model in zip(master_model.parameters(), model.parameters()):\n    #     p_model.data.copy_(p_master.data.float())\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%timeit -n 1 -r 2 train_full()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Epoch 1, Loss: 1.0338482856750488\nEpoch 2, Loss: 0.9935110211372375\nEpoch 3, Loss: 0.9907287955284119\nEpoch 4, Loss: 0.9905089735984802\nEpoch 5, Loss: 0.9904901385307312\nEpoch 6, Loss: 0.9904884696006775\nEpoch 7, Loss: 0.9904883503913879\nEpoch 8, Loss: 0.9904882311820984\nEpoch 9, Loss: 0.9904882311820984\nEpoch 10, Loss: 0.9904882311820984\nEpoch 1, Loss: 0.9904883503913879\nEpoch 2, Loss: 0.9904883503913879\nEpoch 3, Loss: 0.9904883503913879\nEpoch 4, Loss: 0.9904883503913879\nEpoch 5, Loss: 0.9904883503913879\nEpoch 6, Loss: 0.9904883503913879\nEpoch 7, Loss: 0.9904882311820984\nEpoch 8, Loss: 0.9904882311820984\nEpoch 9, Loss: 0.9904882311820984\nEpoch 10, Loss: 0.9904882311820984\n\n\n11.2 s ± 116 ms per loop (mean ± std. dev. of 2 runs, 1 loop each)","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}